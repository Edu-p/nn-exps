{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CIFAR10 with CNNs\n",
        "Simple starter notebook to benchmark your own CNN with PyTorch on the CIFAR-10 dataset.\n",
        "\n",
        "OBS.:\n",
        "\n",
        "- The main code is basically done, so focus on training the models and searching for the best hyperparameters and architectures.\n",
        "- You are not required to use this exact code or even the PyTorch library.\n",
        "- It is recommended to use execution environments with GPU access (such as Google Colab), since larger models will take more time to train.\n",
        "- Remember to document the history of your experiments and which results motivated the changes in subsequent experiments."
      ],
      "metadata": {
        "id": "BjND-9CP7R7n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ErVptyZ7Npv"
      },
      "outputs": [],
      "source": [
        "#@title Libs\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dataset Setup\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)"
      ],
      "metadata": {
        "id": "fcH-AHUK8eGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining the CNN model\n",
        "Here we adapt the LeNet-5 architecture introduced in [*Gradient-based learning applied to document recognition*](https://ieeexplore.ieee.org/document/726791), originally developed to classify handwritten digits.\n",
        "\n",
        "![lenet5](https://www.researchgate.net/publication/359784095/figure/fig2/AS:11431281079624737@1660789284522/Example-of-a-CNN-LeNet-5-14-is-able-to-identify-handwritten-digits-for-zip-code.png)\n",
        "\n",
        "\n",
        "The main change we made here is the number of in/out channels, kernel sizes, padding, etc (enabling better results). It has 2 convolutional layers followed by 2 pooling (subsampling) layers. After the conv. blocks, we pass the feature maps through 2 hidden fully-connected layers to get the most activated neuron with the softmax function. If you want a more detailed explanation, [check this link](https://www.datasciencecentral.com/lenet-5-a-classic-cnn-architecture/) or reach us on Discord :)"
      ],
      "metadata": {
        "id": "6EZqIY5yam_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    # Defining convolution blocks\n",
        "    self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "    self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "\n",
        "    # Defining pooling layer\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    # Defining fully-connected layers\n",
        "    self.fc_hidden1 = nn.Linear(64 * 8 * 8, 120)\n",
        "    self.fc_hidden2 = nn.Linear(120, 84)\n",
        "    self.fc_output = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(nn.ReLU()(self.conv1(x)))\n",
        "    x = self.pool(nn.ReLU()(self.conv2(x)))\n",
        "    x = x.view(x.size(0), -1) # flatten to input into fc layers\n",
        "    x = nn.ReLU()(self.fc_hidden1(x))\n",
        "    x = nn.ReLU()(self.fc_hidden2(x))\n",
        "    x = self.fc_output(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "KLjycMiT8zo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Defining metrics helper\n",
        "\n",
        "def get_scores(targets, predictions):\n",
        "    return {\n",
        "        \"accuracy\": metrics.accuracy_score(targets, predictions),\n",
        "        \"balanced_accuracy\": metrics.balanced_accuracy_score(targets, predictions),\n",
        "        \"precision\": metrics.precision_score(targets, predictions, average=\"weighted\"),\n",
        "        \"recall\": metrics.recall_score(targets, predictions, average=\"weighted\"),\n",
        "        \"f1_score\": metrics.f1_score(targets, predictions, average=\"weighted\")\n",
        "    }"
      ],
      "metadata": {
        "id": "13FaQlXcNvM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hyperparameters\n",
        "\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "tyat2KDLL92I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Loaders\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "OYk-5ANCMIRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Training loop\n",
        "\n",
        "# Build the model\n",
        "cnn = CNN()\n",
        "cnn.cuda()\n",
        "\n",
        "# Setting optimizer up\n",
        "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
        "\n",
        "# Early stopping setup\n",
        "best_loss = float('inf')\n",
        "patience = 5\n",
        "patience_counter = 0\n",
        "\n",
        "# Start training epochs loop\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "  epoch_loss = 0.0\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "\n",
        "    # Forward pass\n",
        "    optimizer.zero_grad()\n",
        "    outputs = cnn(images)\n",
        "\n",
        "    # Backward pass\n",
        "    loss = loss_function(outputs, labels)\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "    if (i+1) % 1000 == 0:\n",
        "      tqdm.write(f' Epoch {epoch + 1}/{num_epochs}, Step {i+1}/{len(train_dataset) // batch_size}, Loss: {loss}')\n",
        "\n",
        "  # Loss avrg\n",
        "  epoch_loss /= len(train_loader)\n",
        "  tqdm.write(f' Epoch {epoch+1} average loss: {epoch_loss:.4f}')\n",
        "\n",
        "  # Early stopping using loss\n",
        "  if epoch_loss < best_loss:\n",
        "    best_loss = epoch_loss\n",
        "    patience_counter = 0\n",
        "  else:\n",
        "    patience_counter += 1\n",
        "    if patience_counter >= patience:\n",
        "      tqdm.write(\"Early stopping triggered.\")\n",
        "      break"
      ],
      "metadata": {
        "id": "XjTJpiboLmSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Evaluate model (accuracy, precision, recall, etc)\n",
        "\n",
        "cnn.eval()\n",
        "predictions = []\n",
        "labels = []\n",
        "for images, label in test_loader:\n",
        "  images = images.cuda()\n",
        "  label = label.cuda()\n",
        "\n",
        "  output = cnn(images)\n",
        "  _, predicted = torch.max(output,1)\n",
        "\n",
        "  predictions.extend(predicted.cpu().numpy())\n",
        "  labels.extend(label.cpu().numpy())\n",
        "\n",
        "scores = get_scores(labels, predictions)\n",
        "print(\"Scores of your model\\n\", scores)"
      ],
      "metadata": {
        "id": "lw6GWhmer78h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# You can change/optimize this as you want\n",
        "- Automatic hyperparameters optimization (Optuna)\n",
        "- Regularization techniques (tip: try dropout)\n",
        "- Use other convolution combinations (e.g. ResNet blocks)\n",
        "- Validation set to track metrics during epochs\n",
        "- Transform input data\n",
        "- ..."
      ],
      "metadata": {
        "id": "bA8HgFj-MjYc"
      }
    }
  ]
}